import os
import requests
import numpy as np
import soundfile as sf
import scipy.signal
from scipy.io.wavfile import write
from basic_pitch.inference import predict
import pretty_midi
import librosa
import mido
from mido import MidiFile, MidiTrack, MetaMessage  # âœ… ì¶”ê°€

def extract_bpm(audio_path: str) -> float:
    try:
        y, sr = librosa.load(audio_path)
        tempo, _ = librosa.beat.beat_track(y=y, sr=sr)

        bpm = tempo
        beat_duration = 60 / bpm  # ì´ˆ
        click_duration = 0.05  # í´ë¦­ ì‚¬ìš´ë“œ ê¸¸ì´

        # ì§§ì€ 'ë”±' ì†Œë¦¬ ìƒì„±
        t = np.linspace(0, click_duration, int(sr * click_duration), False)
        click = 0.5 * np.sin(2 * np.pi * 1000 * t)  # 1kHz í´ë¦­ìŒ

        # ë¬´ìŒ ì‚½ì…
        silence = np.zeros(int(sr * (beat_duration - click_duration)))
        beat = np.concatenate([click, silence])

        # 4ë°•ì í´ë¦­
        click_track = np.tile(beat, 4)
        output_path = audio_path.replace("input", "click")
        write(output_path, sr, click_track.astype(np.float32))

        return float(tempo)
    except Exception as e:
        print(f"âš ï¸ BPM ì¶”ì¶œ ì‹¤íŒ¨: {str(e)} â†’ ê¸°ë³¸ê°’ 120 ì‚¬ìš©")
        return 120.0

def change_bpm(input_path, output_path, new_bpm):
    mid = MidiFile(input_path)
    original_tempo = next(msg.tempo for track in mid.tracks for msg in track if msg.type == 'set_tempo')
    original_bpm = mido.tempo2bpm(original_tempo)
    scaling_factor = new_bpm / original_bpm

    new_mid = MidiFile(type=1)
    new_mid.ticks_per_beat = mid.ticks_per_beat

    # ë©”íƒ€ íŠ¸ë™ ë¨¼ì € ìƒì„±
    meta_track = MidiTrack()
    meta_track.append(MetaMessage('set_tempo', tempo=mido.bpm2tempo(new_bpm), time=0))
    meta_track.append(MetaMessage('time_signature', numerator=4, denominator=4, time=0))
    new_mid.tracks.append(meta_track)
    print(meta_track)

    for track in mid.tracks:
        new_track = MidiTrack()
        for msg in track:
            if msg.is_meta:
                print(msg)
                continue  # ë©”íƒ€ëŠ” ì´ë¯¸ ì²˜ë¦¬í•¨
            else:
                new_time = int(round(msg.time * scaling_factor))
                new_track.append(msg.copy(time=new_time))
        new_mid.tracks.append(new_track)

    new_mid.save(output_path)

def get_wav_duration(file_path):
    with sf.SoundFile(file_path) as f:
        frames = f.frames
        samplerate = f.samplerate
        duration = frames / samplerate
    return duration

def add_dummy_note(input_midi_path, output_midi_path, end_time):
    # 1. MIDI íŒŒì¼ ë¡œë“œ
    midi = pretty_midi.PrettyMIDI(input_midi_path)
    
    # 2. ì²« ë²ˆì§¸ íŠ¸ë™ ì„ íƒ (ë˜ëŠ” ìƒˆ íŠ¸ë™ ìƒì„±)
    if midi.instruments:
        track = midi.instruments[0]  # ê¸°ì¡´ íŠ¸ë™ ì‚¬ìš©
    else:
        track = pretty_midi.Instrument(program=0)  # ìƒˆ íŠ¸ë™ ìƒì„±
        midi.instruments.append(track)
    
    # 3. ì‹œì‘ ë¶€ë¶„ì— ë”ë¯¸ ë…¸íŠ¸ ì¶”ê°€ (E2, velocity=1, 0~0.01ì´ˆ)
    dummy_note = pretty_midi.Note(
        velocity=1,
        pitch=100,
        start=0.0,
        end=0.01
    )

    track.notes.insert(0, dummy_note)  # ì²« ë²ˆì§¸ ìœ„ì¹˜ì— ì‚½ì…

    dummy_note = pretty_midi.Note(
        velocity=1,
        pitch=100,
        start=end_time-0.01,
        end=end_time
    )

    track.notes.append(dummy_note)


    # 4. ìˆ˜ì •ëœ MIDI íŒŒì¼ ì €ì¥
    midi.write(output_midi_path)
    print(f"âœ… ë”ë¯¸ ë…¸íŠ¸ ì¶”ê°€ ì™„ë£Œ: {output_midi_path}")

def preprocess_drum_audio(audio_path):
    y, sr = sf.read(audio_path)
    if len(y.shape) == 2:
        y = np.mean(y, axis=1)
    y_filtered = np.copy(y)
    y_filtered[np.abs(y_filtered) < 0.008] = 0
    return y_filtered, sr

def transcribe_drums_with_omnizart(drums_path: str, storage_path: str) -> dict:
    try:
        # 1. ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬
        y_processed, sr = preprocess_drum_audio(drums_path)
        # 2. ì„ì‹œ íŒŒì¼ ì €ì¥
        temp_path = save_temp_wav(y_processed, sr, drums_path)
        rel_path = os.path.relpath(temp_path, storage_path)
        response = requests.post(
            "http://omnizart:5000/omnizart/drum",
            json={"filename": rel_path}
        )
        return response.json()["output_file"]
    
    except requests.RequestException as e:
        raise RuntimeError(f"Omnizart API error: {str(e)}")
    
def transcribe_music_with_omnizart(music_path: str, storage_path: str) -> dict:
    try:
        # 1. ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬
        y_processed, sr = preprocess_guitar_audio(music_path)
        # 2. ì„ì‹œ íŒŒì¼ ì €ì¥
        temp_path = save_temp_wav(y_processed, sr, music_path)
        rel_path = os.path.relpath(temp_path, storage_path)
        response = requests.post(
            "http://omnizart:5000/omnizart/music",
            json={"filename": rel_path}
        )
        return response.json()["output_file"]
    
    except requests.RequestException as e:
        raise RuntimeError(f"Omnizart API error: {str(e)}")

def preprocess_audio(audio_path):
    """ì˜¤ë””ì˜¤ ë¡œë“œ + ì™„í™”ëœ í•„í„°ë§ (ë¡œìš°íŒ¨ìŠ¤ ì™„í™” + ì‘ì€ ì¡ìŒ ì»·)"""
    y, sr = sf.read(audio_path)

    # ìŠ¤í…Œë ˆì˜¤ë¥¼ ëª¨ë…¸ë¡œ ë³€í™˜
    if len(y.shape) == 2:
        y = np.mean(y, axis=1)

    # 1. ë¶€ë“œëŸ¬ìš´ ë¡œìš°íŒ¨ìŠ¤ í•„í„° (500Hz ì´í•˜ë§Œ ìœ ì§€)
    sos = scipy.signal.butter(4, 500, 'low', fs=sr, output='sos')
    y_filtered = scipy.signal.sosfilt(sos, y)

    # 2. Noise gate (ì•½í•œ ì‹ í˜¸ ì œê±°)
    threshold = 0.003  # ë„ˆë¬´ ë†’ì´ë©´ ì €ì—­ê¹Œì§€ ë‚ ì•„ê°€ë¯€ë¡œ ë‚®ê²Œ ì„¤ì •
    y_filtered[np.abs(y_filtered) < threshold] = 0

    return y_filtered, sr

def save_temp_wav(y, sr, temp_path="temp_processed.wav"):
    sf.write(temp_path, y, sr)
    return temp_path

def filter_short_notes(note_events, min_duration=0.05):
    """ë„ˆë¬´ ì§§ì€ ë…¸íŠ¸ ì œê±°"""
    return [note for note in note_events if (note[1] - note[0]) >= min_duration]

def remove_harmonic_overlaps(note_events, harmonic_distance=12, time_overlap=0.05):
    """ê²¹ì¹˜ëŠ” ë°°ìŒ ì œê±° (ì˜ˆ: ì˜¥íƒ€ë¸Œ ë°°ìŒ ë“±)"""
    filtered_notes = []
    for note in note_events:
        start, end, pitch, confidence = note[:4]  # ì—¬ê¸° ìˆ˜ì •
        is_harmonic = False
        for other in filtered_notes:
            o_start, o_end, o_pitch, _ = other[:4]
            # ì‹œê°„ìƒ ê²¹ì¹˜ê³ , ì˜¥íƒ€ë¸Œ ê´€ê³„ì¼ ê²½ìš°
            if abs(start - o_start) < time_overlap and abs(pitch - o_pitch) in [harmonic_distance, harmonic_distance * 2]:
                if pitch > o_pitch:
                    is_harmonic = True
                break
        if not is_harmonic:
            filtered_notes.append(note)
    return filtered_notes


def note_events_to_midi(note_events, output_midi_path):
    midi = pretty_midi.PrettyMIDI()
    instrument = pretty_midi.Instrument(program=34)  # 34 = Electric Bass (pick)

    if not note_events:
        midi.instruments.append(instrument)
        midi.write(output_midi_path)
        return

    note_events = sorted(note_events, key=lambda x: x[0])

    for note in note_events:
        start, end, pitch, confidence = note[:4]
        if(start<0):
            continue
        velocity = int(confidence * 127)
        velocity = max(20, min(velocity, 127))

        midi_note = pretty_midi.Note(
            velocity=velocity,
            pitch=int(pitch),
            start=start,
            end=end
        )
        instrument.notes.append(midi_note)

    midi.instruments.append(instrument)
    midi.write(output_midi_path)

# âœ… main í•¨ìˆ˜ì—ì„œ bpm ì¸ìë¡œ ë°›ê¸°
def bass_audio_to_midi(input_audio_path, output_midi_path):
    print("[1] ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ ì¤‘...")
    y_filtered, sr = preprocess_audio(input_audio_path)

    print("[2] ì„ì‹œ íŒŒì¼ ì €ì¥ ì¤‘...")
    temp_path = save_temp_wav(y_filtered, sr, input_audio_path)

    print("[3] MIDI ë³€í™˜ ì¤‘...")
    model_output, midi_data, note_events = predict(temp_path)

    print(f"[4] ì¶”ì¶œëœ ë…¸íŠ¸ ìˆ˜: {len(note_events)} â†’ í•„í„°ë§ ì¤‘...")
    note_events = filter_short_notes(note_events, min_duration=0.05)
    note_events = remove_harmonic_overlaps(note_events)
    print(f"[5] í•„í„°ë§ í›„ ë…¸íŠ¸ ìˆ˜: {len(note_events)}")

    print("[6] MIDI ì €ì¥ ì¤‘...")
    note_events_to_midi(note_events, output_midi_path)

    print(f"âœ… ë³€í™˜ ì™„ë£Œ! â†’ {output_midi_path}")

    return output_midi_path

# ê¸°íƒ€ ì±„ë³´
def preprocess_guitar_audio(audio_path):
    """ê¸°íƒ€ ì „ìš© ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬: ë…¸ì´ì¦ˆ ê²Œì´íŠ¸"""
    y, sr = sf.read(audio_path)
    if len(y.shape) == 2:
        y = np.mean(y, axis=1)
    y_filtered = np.copy(y)
    y_filtered[np.abs(y_filtered) < 0.002] = 0
    return y_filtered, sr

def filter_guitar_notes(note_events, min_duration=0.03):
    """ì§§ì€ ë…¸íŠ¸ ë° ë°°ìŒ(7,12,19ìŒ ì°¨ì´) ì œê±°"""
    # 1. ì§§ì€ ë…¸íŠ¸ í•„í„°ë§
    filtered = [note for note in note_events if (note[1] - note[0]) >= min_duration]
    # 2. ë°°ìŒ í•„í„°ë§
    final_notes = []
    for note in filtered:
        start, end, pitch, confidence = note[:4]
        conflict = False
        for existing in final_notes:
            e_start, e_end, e_pitch, _ = existing[:4]
            if abs(start - e_start) < 0.05 and abs(pitch - e_pitch) in [7, 12, 19]:
                conflict = True
                break
        if not conflict:
            final_notes.append(note)
    return final_notes

def create_guitar_midi(note_events, output_path):
    """MIDI ìƒì„±, ê¸°íƒ€ ì‚¬ìš´ë“œ, ë”ë¯¸ë…¸íŠ¸ ì¶”ê°€"""
    midi = pretty_midi.PrettyMIDI()
    guitar = pretty_midi.Instrument(program=26)  # Acoustic Guitar tab
    
    if note_events:
        note_events = sorted(note_events, key=lambda x: x[0])
       
        for note in note_events:
            start, end, pitch, confidence = note[:4]
            if(start<0):
                continue
            velocity = int(confidence * 127)
            guitar.notes.append(pretty_midi.Note(
                velocity=max(20, min(velocity, 127)),
                pitch=int(pitch),
                start=start,
                end=end
            ))
    midi.instruments.append(guitar)
    midi.write(output_path)
    print(f"ğŸ¸ MIDI ìƒì„± ì™„ë£Œ: {output_path}")

def guitar_audio_to_midi(input_path, output_path=None):
    """ê¸°íƒ€ ì˜¤ë””ì˜¤ â†’ MIDI ë³€í™˜ ë©”ì¸ í•¨ìˆ˜"""
    try:
        # 1. ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬
        y_processed, sr = preprocess_guitar_audio(input_path)
        # 2. ì„ì‹œ íŒŒì¼ ì €ì¥
        temp_path = save_temp_wav(y_processed, sr, input_path)
        
        # 3. Basic Pitch ì˜ˆì¸¡
        model_output, midi_data, notes = predict(temp_path)

        # 4. ë…¸íŠ¸ í•„í„°ë§
        # filtered_notes = filter_guitar_notes(notes)
        # 5. MIDI ìƒì„±
        
        create_guitar_midi(notes, output_path)

        return output_path
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None
    

def preprocess_vocal_audio(audio_path):
    """ë³´ì»¬ ì „ìš© ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬: ë…¸ì´ì¦ˆ ê²Œì´íŠ¸"""
    y, sr = sf.read(audio_path)
    if len(y.shape) == 2:
        y = np.mean(y, axis=1)
    y_filtered = np.copy(y)
    y_filtered[np.abs(y_filtered) < 0.002] = 0
    return y_filtered, sr

def create_vocal_midi(note_events, output_path):
    """MIDI ìƒì„±, ë³´ì»¬ ì‚¬ìš´ë“œ, ë”ë¯¸ë…¸íŠ¸ ì¶”ê°€"""
    midi = pretty_midi.PrettyMIDI()
    vocal = pretty_midi.Instrument(program=26)  # vocal 
    if note_events:
        note_events = sorted(note_events, key=lambda x: x[0])
       
        for note in note_events:
            start, end, pitch, confidence = note[:4]
            if(start<0):
                continue
            velocity = int(confidence * 127)
            vocal.notes.append(pretty_midi.Note(
                velocity=max(20, min(velocity, 127)),
                pitch=int(pitch),
                start=start,
                end=end
            ))
    midi.instruments.append(vocal)
    midi.write(output_path)
    print(f" MIDI ìƒì„± ì™„ë£Œ: {output_path}")

def vocal_audio_to_midi(input_path, output_path=None):
    """ê¸°íƒ€ ì˜¤ë””ì˜¤ â†’ MIDI ë³€í™˜ ë©”ì¸ í•¨ìˆ˜"""
    try:
        # 1. ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬
        y_processed, sr = preprocess_vocal_audio(input_path)
        # 2. ì„ì‹œ íŒŒì¼ ì €ì¥
        temp_path = save_temp_wav(y_processed, sr, input_path)
        
        # 3. Basic Pitch ì˜ˆì¸¡
        model_output, midi_data, notes = predict(temp_path)

        # 5. MIDI ìƒì„±
        
        create_vocal_midi(notes, output_path)

        return output_path
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None